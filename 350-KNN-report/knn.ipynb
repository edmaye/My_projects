{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1: K-Nearest Neighbors Classification (15 marks)"
   ],
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "W_oI1y6-cY4d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Student Name:\n",
    "\n",
    "Student ID:"
   ],
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "XIBjsAqjcY4e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General info"
   ],
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "1Huv7ALVcY4f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <b>Due date</b>: Friday, 13 August 2021 5pm\n",
    "\n",
    "<b>Submission method</b>: Canvas submission\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -10% per day (both week and weekend days counted up to 5 days)\n",
    "<ul>\n",
    "    <li>one day late, -1.5;</li>\n",
    "    <li>two days late, -3.0;</li>\n",
    "    <li>three days late, -4.5;</li>\n",
    "    <li>four days late, -6.0;</li>\n",
    "    <li>five days late, -7.5;</li>\n",
    "</ul>\n",
    "\n",
    "<b>Marks</b>: 15% of mark for class. \n",
    "\n",
    "\n",
    "<b>Materials</b>: See [Using Jupyter Notebook and Python page](https://canvas.lms.unimelb.edu.au/courses/105477/pages/python-and-jupyter-notebooks?module_item_id=2613813) on Canvas (under Modules> Coding Resources) for information on the basic setup required for this class, including an iPython notebook viewer and the python packages Numpy, Scipy, Scikit-Learn. You can also use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>.  \n",
    "\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it. We reserve the right to deduct up to 2 marks for unreadable or exessively inefficient code.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via Canvas. Minor changes and clarifications will be announced on the discussion board (Piazza -> Assignment_1); we recommend you check it regularly.\n",
    "\n",
    "<b>Academic misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. Please check the <a href=\"https://canvas.lms.unimelb.edu.au/courses/105477/modules\">CIS Academic Honesty training</a> for more information. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "Please carefully read and fill out the <b>Authorship Declaration</b> form at the bottom of the page. Failure to fill out this form results in the following deductions: \n",
    "<UL TYPE=”square”>\n",
    "<LI>missing Authorship Declaration at the bottom of the page, -5.0\n",
    "<LI>incomplete or unsigned Authorship Declaration at the bottom of the page, -3.0\n",
    "</UL>"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "p07JVvoScY4g"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "wseHhYGScY4g"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this assignment, you will implement the K-nearest neighbor (KNN) classification algorithm and apply it to a real-world machine learning data set. In particular we will classify instances into seven image categories. \n",
    "\n",
    "You will read in the dataset into a feature and a label set (Q1). You will implement a preprocessing function on the feature set (Q2). You will create a train and a test set for the original as well as the processed data (Q3). You will implement different distance functions (Q4). You will implement a KNN classifier (Q5). You will apply and evaluate your classifier on the data set exploring different parameters/settings (Q6). Finally, you will critically discuss your results (Q7)."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "wH9UvbJTcY4h"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 1: Loading the data (1.5 marks)\n",
    "\n",
    "**Instructions:** For this assignment we will develop a K-Nearest Neighbors (KNN) classifier to classify image regions into pre-defined categories of outdoor spaces, namely\n",
    "```\n",
    "1: brickface\n",
    "2: sky\n",
    "3: foliage\n",
    "4: cement\n",
    "5: window\n",
    "6: path\n",
    "7: grass\n",
    "```\n",
    "\n",
    "We use a subset of the Image Segmentation data set from the UCI Machine learning repository.\n",
    "\n",
    "The original data can be found here: https://archive.ics.uci.edu/ml/datasets/image+segmentation. \n",
    "\n",
    "The dataset consists of 205 instances. Each instance corresponds to a 3x3 region of an outdoor image which has a unique identifier (the index of the instance; first field) and is characterized with 16 numeric (continuous) features named f1, f2, ..., f16.\n",
    "\n",
    "You need to first obtain this dataset, which is on Canvas (assignment 1). The files we will be using are called *segmentation.features* and *segmentation.labels*. Make sure the files are saved in the same folder as this notebook.\n",
    "\n",
    "Both files are in comma-separated value format.\n",
    "\n",
    "*segmentation.features* contains 205 instances, one instance per line. The first field is the unique instance identifier (the index). The following fields contain the 16 continuous features.\n",
    "\n",
    "*segmentation.labels* contains the gold labels (i.e., one of the seven classes above), for one instance per line. Again, the first field is the instance identifier, and the second field the instance label.\n",
    "\n",
    "**Task**: Read the two files  \n",
    "1. create a **features** set (list of features for all instances in the segmentation.* files - **Note that your feature values must not be rounded**)\n",
    "2. create a **labels** set (list of labels for all instances in the dataset). \n",
    "\n",
    "**Check**: Use the assertion statements in *\"For your testing\"* to validate your code."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "data = open(\"segmentation.features\", 'r').readlines()\r\n",
    "gold = open(\"segmentation.labels\", 'r').readlines()\r\n",
    "\r\n",
    "features = []\r\n",
    "labels   = []\r\n",
    "\r\n",
    "\r\n",
    "###########################\r\n",
    "## YOUR CODE BEGINS HERE\r\n",
    "###########################\r\n",
    "\r\n",
    "for data_line, label_line in zip(data,gold):\r\n",
    "    feature = list(map(float,data_line.split(',')[1:])) # data_line是一个字符串，每个数据以逗号相隔，因此用split()分离\r\n",
    "    features.append(feature)\r\n",
    "    label = int(label_line.split(',')[1])\r\n",
    "    labels.append(label)\r\n",
    "\r\n",
    "\r\n",
    "###########################\r\n",
    "## YOUR CODE BEGINS HERE\r\n",
    "###########################\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b> For your testing </b>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "assert len(features[0]) == len(features[-1])\r\n",
    "assert len(labels) == len(features)\r\n",
    "assert round(features[5][4],2) == 4.44 and labels[5]==6\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2-A: Data Processing (1.0 marks)\n",
    "**Instructions:** Write a function that processes instances based on the range of feature values, the description below shows the data processing for feature $j$ of instance $i$:\n",
    "\n",
    "$x'_{ij}=\\frac{x_{ij}-min(x_{*j})}{max(x_{*j})-min(x_{*j})}$\n",
    "\n",
    "where $*$ denotes all possible instance identifiers. For example $x_{*1}$ is all the possible values for the first feature vector.   \n",
    "\n",
    "Your function will take as input \n",
    "- features\n",
    "\n",
    "It returns as output\n",
    "- processed features\n",
    "\n",
    "**You should implement the function from scratch yourself**, i.e., <b> you must not</b> use an existing implementation in any Python library."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "\r\n",
    "###########################\r\n",
    "## YOUR CODE BEGINS HERE\r\n",
    "###########################\r\n",
    "\r\n",
    "def process_data(features):\r\n",
    "    pr_features = []\r\n",
    "    # insert code here\r\n",
    "\r\n",
    "    # 预先计算出每一列对应的最大值、最小值\r\n",
    "    mmax, mmin = [0]*len(features[0]), [999]*len(features[0])\r\n",
    "    for ins_features in features:\r\n",
    "        for j in range(len(ins_features)):\r\n",
    "            mmax[j] = max(mmax[j], ins_features[j]) # 保存最大值\r\n",
    "            mmin[j] = min(mmin[j], ins_features[j]) # 保存最小值\r\n",
    "    # 对每个instance的feature向量进行归一化\r\n",
    "    for ins_features in features:\r\n",
    "        norm_feature = [ (x-mmin[j])/(mmax[j]-mmin[j]) for j,x in enumerate(ins_features)]  # 按照题目要求中的公式，对一行中每一列数据单独进行计算\r\n",
    "        pr_features.append(norm_feature)\r\n",
    "    return pr_features\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "###########################\r\n",
    "## YOUR CODE ENDS HERE\r\n",
    "###########################\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b> For your testing </b>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "assert process_data([[3,5],[1,7],[2,9]]) == [[1,0],[0,0.5],[0.5,1]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2-B: Data Processing discussion (1.0 marks)\n",
    "(a) Imagine that for feature $j$, $min(x_{*j}) = max(x_{*j})$. Would you keep this feature in your dataset? (b) Why?\n",
    "\n",
    "<b>your answer must be no more than 1-2 sentences.</b>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2-B (a). No\r\n",
    "\r\n",
    "2-B (b). Because for all instances, the value of feature j is the same, so it does not help to distinguish between different instances. Instead, it will bring redundancy in model calculations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 3: Train and test datasets (0.5 marks)\n",
    "\n",
    "**Task**:   \n",
    "1. create a **train_feature** set (list of features for the first 195 instances in the features), and a **train_label** set (list of labels for the corresponding).\n",
    "2. create a **test_feature** set (list of features of the remaining instances in the features) and a **test_label** set (list of labels for the corresponding). \n",
    "3. create a **pr_train_feature** set (list of processed features for the first 195 instances in the pr_features)\n",
    "4. create a **pr_test_feature** set (list of processed features of the remaining instances in the pr_features)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "train_features = []\r\n",
    "train_labels   = []\r\n",
    "test_features = []\r\n",
    "test_labels   = []\r\n",
    "pr_train_features = []\r\n",
    "pr_test_features = []\r\n",
    "###########################\r\n",
    "## YOUR CODE BEGINS HERE\r\n",
    "###########################\r\n",
    "pr_features = process_data(features)    # 用前面定义好的函数得到processed features\r\n",
    "\r\n",
    "train_features = features[:195]\r\n",
    "train_labels   = labels[:195]\r\n",
    "test_features = features[195:]\r\n",
    "test_labels   = labels[195:]\r\n",
    "pr_train_features = pr_features[:195]\r\n",
    "pr_test_features = pr_features[195:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>For your testing</b>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "assert len(train_features) == len(train_labels)\r\n",
    "assert len(test_features[0])==len(test_features[-1])\r\n",
    "assert train_features[10][0]==0 and train_labels[10]==3\r\n",
    "assert len(pr_train_features) == len(train_labels)\r\n",
    "assert round(pr_test_features[1][2],2)== 0.13"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 4-A: Distance Functions (2.0 marks)\r\n",
    "\r\n",
    "<b>Instructions</b>: Implement the two distance functions specified below. Use <b>only</b> the library imported below, i.e., <b>do not</b> use implementations from any other Python library. \r\n",
    "\r\n",
    "1. **General distance (defined below)** \r\n",
    "    \r\n",
    "    $d(x,y)=(\\sum_{i=1}^{|F|}|x_i-y_i|^p)^{1/p}$\r\n",
    "    \r\n",
    "    where $|F|$ is the number of features\r\n",
    "    \r\n",
    "Your function will take as input\r\n",
    "- Two feature vectors\r\n",
    "- Power p\r\n",
    "\r\n",
    "It returns as output\r\n",
    "- The distance between the two feature vectors (float)\r\n",
    "    \r\n",
    "\r\n",
    "2. **Cosine distance (Refer to the lecture 3 slides)**\r\n",
    "\r\n",
    "Your function will take as input \r\n",
    "- Two feature vectors\r\n",
    "\r\n",
    "It returns as output\r\n",
    "- The distance between the two feature vectors (float)\r\n",
    "\r\n",
    "**You should implement the function from scratch yourself**, i.e., <b> you must not</b> use an existing implementation in any Python library."
   ],
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "V2OlvNAicY4i"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "import math\r\n",
    "\r\n",
    "#########################\r\n",
    "# Your answer BEGINS HERE\r\n",
    "#########################\r\n",
    "def general_distance(fv1, fv2, p):\r\n",
    "    # insert code here\r\n",
    "    distance = 0.0\r\n",
    "    for x1,x2 in zip(fv1,fv2):\r\n",
    "        distance += math.pow(abs(x1-x2),p)\r\n",
    "    distance = math.pow(distance, 1.0/p)\r\n",
    "    return distance\r\n",
    "\r\n",
    "\r\n",
    "def cosine_distance(fv1, fv2):\r\n",
    "    # insert code here\r\n",
    "    v1, v2, v3 = 0.0, 0.0, 0.0\r\n",
    "    for x1,x2 in zip(fv1,fv2):\r\n",
    "        v1 += x1*x2\r\n",
    "        v2 += x1*x1\r\n",
    "        v3 += x2*x2\r\n",
    "    v2 = math.sqrt(v2)\r\n",
    "    v3 = math.sqrt(v3)\r\n",
    "    cosine = v1/(v2*v3)\r\n",
    "    distance = 1 - cosine\r\n",
    "    return distance\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#########################\r\n",
    "# Your answer ENDS HERE\r\n",
    "#########################\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10593,
     "status": "ok",
     "timestamp": 1588139440049,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "szPlY9PIcY4j",
    "outputId": "218560c5-6e80-4a8b-bfaf-5cb46b90f34c",
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>For your testing: </b>"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "JTt3T9fycY4p"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "assert round(general_distance([1,0],[0.5,1],3),2)==1.04\r\n",
    "assert cosine_distance([1,1,1,1], [0,1,0,0])==0.5"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCkSP91lcY4q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 4-B: General Distance Discussion (0.5 marks)\r\n",
    "\r\n",
    "(a) What power p of general distance function will result in Euclidean distance?\r\n",
    "(b) What power p of general distance function will result in Manhattan distance?\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4-B (a).  Power p should be 2.\r\n",
    "\r\n",
    "4-B (b).  Power p should be 1.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 5: KNN Classifier (2.0 marks)\n",
    "\n",
    "<b>Instructions</b>: Here, you implement your KNN classifier.\n",
    "\n",
    "function input \n",
    "- training data features\n",
    "- training labels \n",
    "- test data features\n",
    "- parameter K\n",
    "- distance function(s) based on which nearest neighbors will be identified\n",
    "- optional parameter for the distance functions (*args)   \n",
    "   \n",
    "\n",
    "and returns as output\n",
    "- the predicted labels for the test data\n",
    "\n",
    "**You should implement the classifier from scratch yourself**, i.e., <b> you must not</b> use an existing implementation in any Python library.\n",
    "\n",
    "**Ties among distances**. If there are more than K instances with the same (smallest) distance value, consider the first K.\n",
    "\n",
    "**Ties at prediction time.** Ties can also occur at class prediction time when two (or more) classes are supported by the same number of neighbors. You may break the ties by considering the smaller class label (if necessary). E.g., if there are the same number of nearest neighbors for both labels 1 and 3, you may select 1 as the predicted label.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "def KNN(train_features, train_labels, test_features, k, dist_fun, *args):\r\n",
    "    \r\n",
    "    predictions = []\r\n",
    "    \r\n",
    "    ###########################\r\n",
    "    ## YOUR CODE BEGINS HERE\r\n",
    "    ###########################\r\n",
    "    def get_value(data):    # 用于排序，指定用向量的第几个数进行排序\r\n",
    "        return data[0]\r\n",
    "    # 每个test样本单独处理\r\n",
    "    for test_feature in test_features:\r\n",
    "        distance_list = []\r\n",
    "        # 与训练集所有样本逐一计算距离函数\r\n",
    "        for train_feature, label in zip(train_features, train_labels):\r\n",
    "            distance = dist_fun(train_feature, test_feature, *args)\r\n",
    "            distance_list.append([distance, label])\r\n",
    "        # 排序\r\n",
    "        distance_list.sort(key=get_value)     # 按照distance值从小到大排序\r\n",
    "        # 统计前k次各类别出现的频数\r\n",
    "        label_count = {}\r\n",
    "        for i in range(k):\r\n",
    "            _, label = distance_list[i]\r\n",
    "            label_count[label] = label_count.get(label, 0) + 1\r\n",
    "        label_count = sorted(label_count.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)   # 对字典的值，从大到小排序\r\n",
    "        # 将出现频数最大的类别作为预测结果\r\n",
    "        predictions.append(label_count[0][0])\r\n",
    "    ###########################\r\n",
    "    ## YOUR CODE ENDS HERE\r\n",
    "    ###########################\r\n",
    "        \r\n",
    "    return predictions       "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1588139482398,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "W6rdnrOXcY41",
    "outputId": "8d2391db-d5c0-4ea2-ea83-850e79bffd5c",
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>For your testing:</b>"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "cWgLNH3LcY45"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "assert KNN([[1,1],[5,5],[1,2]], [1,0,1], [[1,1]], 1, cosine_distance) == [1]\r\n",
    "assert KNN([[1,1],[5,5],[1,2]], [1,0,1], [[1,1]], 1, general_distance,2) == [1]\r\n",
    "assert KNN([[1,1],[4,5],[1,2], [5,4]], [1,0,0,1], [[1,1]], 3, general_distance,2) == [0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 6-A: Applying your KNN classifiers to the Segmentation Dataset (1.5 marks)\r\n",
    "\r\n",
    "**Using the functions you have implemented in Question 4, 5 and the original train and test in Question 3, please**\r\n",
    "\r\n",
    "<b> 1. </b>\r\n",
    "construct four KNN classifiers with K=1, K=3, K=30, K=120. Use <b>only</b> the library imported below, i.e., <b>do not</b> use implementations from any other Python library.  \r\n",
    "\r\n",
    "<b> Distance functions: </b>\r\n",
    "<ul type=\"a\">\r\n",
    "    <li>Euclidean distance (Use general distance in 4-A)</li>    \r\n",
    "    <li>Manhattan distance (Use general distance in 4-A)</li>    \r\n",
    "    <li>Cosine distance (Use Cosine distance in 4-A)</li>\r\n",
    "</ul>\r\n",
    "<b> Train and test data: </b> \r\n",
    "<ul type=\"a\">\r\n",
    "    <li>Original train and test (train_features and test_features)</li>     \r\n",
    "</ul>    \r\n",
    "\r\n",
    "You will create a total of 12 (3 distance functions x 4 K values) classifiers.\r\n",
    "\r\n",
    "<b> 2. </b>\r\n",
    "Compute the test accuracy for each model using the following function:\r\n",
    "<ul type=\"a\">\r\n",
    "    <li>precision_score(gold, predict, average='micro')</li>\r\n",
    "</ul>\r\n",
    "    this function returns the fraction of correct labels over all predicted labels (predict).\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "# 1. Predict test labels with each KNN classifier\r\n",
    "\r\n",
    "########################\r\n",
    "# Your code STARTS HERE\r\n",
    "########################\r\n",
    "predictions_euc_1 = KNN(train_features, train_labels, test_features, 1, general_distance, 2)\r\n",
    "predictions_euc_3 = KNN(train_features, train_labels, test_features, 3, general_distance, 2)\r\n",
    "predictions_euc_30 = KNN(train_features, train_labels, test_features, 30,  general_distance, 2)\r\n",
    "predictions_euc_120 = KNN(train_features, train_labels, test_features, 120, general_distance, 2)\r\n",
    "predictions_man_1 = KNN(train_features, train_labels, test_features, 1, general_distance, 1)\r\n",
    "predictions_man_3 = KNN(train_features, train_labels, test_features, 3, general_distance, 1)\r\n",
    "predictions_man_30 = KNN(train_features, train_labels, test_features, 30,  general_distance, 1)\r\n",
    "predictions_man_120 = KNN(train_features, train_labels, test_features, 120, general_distance, 1)\r\n",
    "predictions_cos_1 = KNN(train_features, train_labels, test_features, 1,  cosine_distance)\r\n",
    "predictions_cos_3 = KNN(train_features, train_labels, test_features, 3,  cosine_distance)\r\n",
    "predictions_cos_30 = KNN(train_features, train_labels, test_features, 30,  cosine_distance)\r\n",
    "predictions_cos_120 = KNN(train_features, train_labels, test_features, 120, cosine_distance)\r\n",
    "# 2. Compute the accuracy scores \r\n",
    "accuracy_knn_euc_1 = precision_score(test_labels, predictions_euc_1, average='micro')\r\n",
    "accuracy_knn_euc_3 = precision_score(test_labels, predictions_euc_1, average='micro')\r\n",
    "accuracy_knn_euc_30 = precision_score(test_labels, predictions_euc_1, average='micro')\r\n",
    "accuracy_knn_euc_120 = precision_score(test_labels, predictions_euc_1, average='micro')\r\n",
    "accuracy_knn_man_1 = precision_score(test_labels, predictions_man_1, average='micro')\r\n",
    "accuracy_knn_man_3 = precision_score(test_labels, predictions_man_3, average='micro')\r\n",
    "accuracy_knn_man_30 = precision_score(test_labels, predictions_man_30, average='micro')\r\n",
    "accuracy_knn_man_120 = precision_score(test_labels, predictions_man_120, average='micro')\r\n",
    "accuracy_knn_cos_1 = precision_score(test_labels, predictions_cos_1, average='micro')\r\n",
    "accuracy_knn_cos_3 = precision_score(test_labels, predictions_cos_3, average='micro')\r\n",
    "accuracy_knn_cos_30 = precision_score(test_labels, predictions_cos_30, average='micro')\r\n",
    "accuracy_knn_cos_120 = precision_score(test_labels, predictions_cos_120, average='micro')\r\n",
    "\r\n",
    "########################\r\n",
    "# Your code ENDS HERE\r\n",
    "########################\r\n",
    "\r\n",
    "print(\"Euclidean\")\r\n",
    "print(accuracy_knn_euc_1)\r\n",
    "print(accuracy_knn_euc_3)\r\n",
    "print(accuracy_knn_euc_30)\r\n",
    "print(accuracy_knn_euc_120)\r\n",
    "print(\"Manhattan\")\r\n",
    "print(accuracy_knn_man_1)\r\n",
    "print(accuracy_knn_man_3)\r\n",
    "print(accuracy_knn_man_30)\r\n",
    "print(accuracy_knn_man_120)\r\n",
    "print(\"Cosine\")\r\n",
    "print(accuracy_knn_cos_1)\r\n",
    "print(accuracy_knn_cos_3)\r\n",
    "print(accuracy_knn_cos_30)\r\n",
    "print(accuracy_knn_cos_120)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Euclidean\n",
      "0.7\n",
      "0.7\n",
      "0.7\n",
      "0.7\n",
      "Manhattan\n",
      "0.7\n",
      "0.8\n",
      "0.7\n",
      "0.3\n",
      "Cosine\n",
      "0.8\n",
      "0.9\n",
      "0.8\n",
      "0.2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 6-B: Applying your KNN classifiers to the processed Segmentation Dataset (1.5 marks)\n",
    "\n",
    "**Using the functions you have implemented in Question 4, 5 and the processed train and test in Question 3, please**\n",
    "\n",
    "<b> 1. </b>\n",
    "construct four KNN classifiers with K=1, K=3, K=30, K=120. Use <b>only</b> the library imported below, i.e., <b>do not</b> use implementations from any other Python library.   \n",
    "\n",
    "<b> Distance functions: </b>\n",
    "<ul type=\"a\">\n",
    "    <li>Euclidean distance (Use general distance in 4-A)</li>    \n",
    "    <li>Manhattan distance (Use general distance in 4-A)</li>    \n",
    "    <li>Cosine distance (Use Cosine distance in 4-A)</li>\n",
    "</ul>\n",
    "    \n",
    "<b> Train and test data: </b> \n",
    "<ul type=\"a\">\n",
    "    <li>Processed train and test (pr_train_features and pr_test_features)</li>\n",
    "</ul>\n",
    "    \n",
    "\n",
    "You will create a total of 12 (3 distance functions x 4 K values) classifiers.\n",
    "\n",
    "<b> 2. </b>\n",
    "Compute the test accuracy for each model using the following function:\n",
    "<ul type=\"a\">\n",
    "    <li>precision_score(gold, predict, average='micro')</li>\n",
    "</ul>\n",
    "\n",
    "    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "\r\n",
    "# 1. Predict test labels with each KNN classifier\r\n",
    "\r\n",
    "########################\r\n",
    "# Your code STARTS HERE\r\n",
    "########################\r\n",
    "predictions_euc_1 = KNN(pr_train_features, train_labels, pr_test_features, 1, general_distance, 2)\r\n",
    "predictions_euc_3 = KNN(pr_train_features, train_labels, pr_test_features, 3, general_distance, 2)\r\n",
    "predictions_euc_30 = KNN(pr_train_features, train_labels, pr_test_features, 30,  general_distance, 2)\r\n",
    "predictions_euc_120 = KNN(pr_train_features, train_labels, pr_test_features, 120, general_distance, 2)\r\n",
    "predictions_man_1 = KNN(pr_train_features, train_labels, pr_test_features, 1, general_distance, 1)\r\n",
    "predictions_man_3 = KNN(pr_train_features, train_labels, pr_test_features, 3, general_distance, 1)\r\n",
    "predictions_man_30 = KNN(pr_train_features, train_labels, pr_test_features, 30,  general_distance, 1)\r\n",
    "predictions_man_120 = KNN(pr_train_features, train_labels, pr_test_features, 120, general_distance, 1)\r\n",
    "predictions_cos_1 = KNN(pr_train_features, train_labels, pr_test_features, 1,  cosine_distance)\r\n",
    "predictions_cos_3 = KNN(pr_train_features, train_labels, pr_test_features, 3,  cosine_distance)\r\n",
    "predictions_cos_30 = KNN(pr_train_features, train_labels, pr_test_features, 30,  cosine_distance)\r\n",
    "predictions_cos_120 = KNN(pr_train_features, train_labels, pr_test_features, 120, cosine_distance)\r\n",
    "# 2. Compute the accuracy scores \r\n",
    "accuracy_pr_knn_euc_1 = precision_score(test_labels, predictions_euc_1, average='micro')\r\n",
    "accuracy_pr_knn_euc_3 = precision_score(test_labels, predictions_euc_1, average='micro')\r\n",
    "accuracy_pr_knn_euc_30 = precision_score(test_labels, predictions_euc_1, average='micro')\r\n",
    "accuracy_pr_knn_euc_120 = precision_score(test_labels, predictions_euc_1, average='micro')\r\n",
    "accuracy_pr_knn_man_1 = precision_score(test_labels, predictions_man_1, average='micro')\r\n",
    "accuracy_pr_knn_man_3 = precision_score(test_labels, predictions_man_3, average='micro')\r\n",
    "accuracy_pr_knn_man_30 = precision_score(test_labels, predictions_man_30, average='micro')\r\n",
    "accuracy_pr_knn_man_120 = precision_score(test_labels, predictions_man_120, average='micro')\r\n",
    "accuracy_pr_knn_cos_1 = precision_score(test_labels, predictions_cos_1, average='micro')\r\n",
    "accuracy_pr_knn_cos_3 = precision_score(test_labels, predictions_cos_3, average='micro')\r\n",
    "accuracy_pr_knn_cos_30 = precision_score(test_labels, predictions_cos_30, average='micro')\r\n",
    "accuracy_pr_knn_cos_120 = precision_score(test_labels, predictions_cos_120, average='micro')\r\n",
    "\r\n",
    "########################\r\n",
    "# Your code ENDS HERE\r\n",
    "########################\r\n",
    "\r\n",
    "print(\"Euclidean\")\r\n",
    "print(accuracy_pr_knn_euc_1)\r\n",
    "print(accuracy_pr_knn_euc_3)\r\n",
    "print(accuracy_pr_knn_euc_30)\r\n",
    "print(accuracy_pr_knn_euc_120)\r\n",
    "print(\"Manhattan\")\r\n",
    "print(accuracy_pr_knn_man_1)\r\n",
    "print(accuracy_pr_knn_man_3)\r\n",
    "print(accuracy_pr_knn_man_30)\r\n",
    "print(accuracy_pr_knn_man_120)\r\n",
    "print(\"Cosine\")\r\n",
    "print(accuracy_pr_knn_cos_1)\r\n",
    "print(accuracy_pr_knn_cos_3)\r\n",
    "print(accuracy_pr_knn_cos_30)\r\n",
    "print(accuracy_pr_knn_cos_120)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Euclidean\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "Manhattan\n",
      "0.8\n",
      "0.9\n",
      "0.7\n",
      "0.2\n",
      "Cosine\n",
      "0.8\n",
      "0.9\n",
      "0.7\n",
      "0.4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 7: Discussion (3.5 marks)\r\n",
    "1. (a) Which parameter K resulted in the worst performance (6-A)? (b) Why? (c) How can we remedy this problem?\r\n",
    "\r\n",
    "2. (a) How does the accuracy of KNN change by using the processed data (6-B)? (b) Which distance metrics are least and most affected by the data processing step? Why? \r\n",
    "\r\n",
    "3. Imagine a scenario where for the same segmentation dataset, instead of 7 labels, we had a binary label, i.e., 1: Window 0: Others, (a) would the accuracy measure used in Q-6 be appropriate? (b) Why?\r\n",
    "\r\n",
    "\r\n",
    "<b>Each question should be answered in no more than 2-3 sentences.</b>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1(a).  When K = 120, the performance of KNN is the worst.\r\n",
    "\r\n",
    "1(b).  When k is too large, the model may be underfitted. There may be a problem of unbalanced categories. A certain category may not be the correct answer, but its number is relatively large, making the first k results contain a large number of such categories, causing misjudgment.\r\n",
    "\r\n",
    "1(c).  The results can be weighted by distance to reduce the impact of categories with low confidence but more numbers\r\n",
    "\r\n",
    "2(a).  The accuracy rate has been improved overall (except for the extreme case of k=120)\r\n",
    "\r\n",
    "2(b).  Cosine is the least and Euclidean is the most. The difference in calculation formula leads to this result, for the cosine distance, it originally has a certain normalization effect, so it is less affected. For the Euclidean distance, the preprocessed data dimension is smaller, so that the calculated distance is nonlinearly compressed (because of sqrt function), which affects the final result.\r\n",
    "\r\n",
    "3(a).  It is no longer suitable, ROC, AUC and other indicators should be better.\r\n",
    "\r\n",
    "3(b).  Combining the six categories outside Window into one category will result in a serious imbalance in the number of categories. At this time, even if the predictive ability of the window category is very poor, because of its small number, it has little effect on the accuracy (relative to another category). Therefore, other more comprehensive indicators are needed.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Authorship Declaration</b>:\n",
    "\n",
    "   (1) I certify that the program contained in this submission is completely\n",
    "   my own individual work, except where explicitly noted by comments that\n",
    "   provide details otherwise.  I understand that work that has been developed\n",
    "   by another student, or by me in collaboration with other students,\n",
    "   or by non-students as a result of request, solicitation, or payment,\n",
    "   may not be submitted for assessment in this subject.  I understand that\n",
    "   submitting for assessment work developed by or in collaboration with\n",
    "   other students or non-students constitutes Academic Misconduct, and\n",
    "   may be penalized by mark deductions, or by other penalties determined\n",
    "   via the University of Melbourne Academic Honesty Policy, as described\n",
    "   at https://academicintegrity.unimelb.edu.au.\n",
    "\n",
    "   (2) I also certify that I have not provided a copy of this work in either\n",
    "   softcopy or hardcopy or any other form to any other student, and nor will\n",
    "   I do so until after the marks are released. I understand that providing\n",
    "   my work to other students, regardless of my intention or any undertakings\n",
    "   made to me by that other student, is also Academic Misconduct.\n",
    "\n",
    "   (3) I further understand that providing a copy of the assignment\n",
    "   specification to any form of code authoring or assignment tutoring\n",
    "   service, or drawing the attention of others to such services and code\n",
    "   that may have been made available via such a service, may be regarded\n",
    "   as Student General Misconduct (interfering with the teaching activities\n",
    "   of the University and/or inciting others to commit Academic Misconduct).\n",
    "   I understand that an allegation of Student General Misconduct may arise\n",
    "   regardless of whether or not I personally make use of such solutions\n",
    "   or sought benefit from such actions.\n",
    "\n",
    "   <b>Signed by</b>: [Enter your full name and student number here before submission]\n",
    "   \n",
    "   <b>Dated</b>: [Enter the date that you \"signed\" the declaration]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "word-similarity.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "6b8802724ec1d13da25504e0ebf5110b1ac5b253f148618a9788a538ba90110c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}